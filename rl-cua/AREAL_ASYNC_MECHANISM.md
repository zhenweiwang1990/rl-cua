# AReaL å¼‚æ­¥ Rollout æœºåˆ¶è¯¦è§£

## ä¸€ã€æ ¸å¿ƒé—®é¢˜ï¼šä¸ºä»€ä¹ˆéœ€è¦å¼‚æ­¥ï¼Ÿ

### 1.1 åŒæ­¥è®­ç»ƒçš„ç—›ç‚¹

**ä¼ ç»ŸåŒæ­¥è®­ç»ƒæµç¨‹**ï¼ˆä½ å½“å‰çš„æ–¹å¼ï¼‰ï¼š

```
Step 1: æ”¶é›†æ‰€æœ‰ rollouts (ç­‰å¾…å®Œæˆ)
  â”œâ”€ Rollout 1: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 80% (è¿˜åœ¨è¿è¡Œ)
  â”œâ”€ Rollout 2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (å®Œæˆï¼Œç­‰å¾…ä¸­...)
  â”œâ”€ Rollout 3: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 40% (è¿˜åœ¨è¿è¡Œ)
  â””â”€ Rollout 4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (å®Œæˆï¼Œç­‰å¾…ä¸­...)

Step 2: æ‰€æœ‰å®Œæˆåæ‰èƒ½è¿›å…¥è®­ç»ƒ
  â””â”€ GPU è®­ç»ƒå•å…ƒï¼šç©ºé—²ç­‰å¾…ä¸­... â¸ï¸

Step 3: è®­ç»ƒå®Œæˆåï¼Œé‡æ–°æ”¶é›† rollouts
  â””â”€ GPU æ¨ç†å•å…ƒï¼šç©ºé—²ç­‰å¾…ä¸­... â¸ï¸
```

**é—®é¢˜**ï¼š
- âŒ GPU åˆ©ç”¨ç‡ä½ï¼šè®­ç»ƒ GPU åœ¨ç­‰å¾… rollout æ”¶é›†ï¼Œæ¨ç† GPU åœ¨ç­‰å¾…è®­ç»ƒå®Œæˆ
- âŒ åºåˆ—åŒ–æ‰§è¡Œï¼šå¿…é¡»ç­‰å¾…æœ€æ…¢çš„ rollout å®Œæˆ
- âŒ èµ„æºæµªè´¹ï¼šä¸¤ä¸ªé˜¶æ®µçš„ GPU ä¸èƒ½åŒæ—¶å·¥ä½œ

### 1.2 å¼‚æ­¥è®­ç»ƒçš„ä¼˜åŠ¿

**AReaL å¼‚æ­¥æµç¨‹**ï¼š

```
æ—¶é—´çº¿ï¼š

T0: å¼€å§‹æ”¶é›† Rollout Batch 1
  â”œâ”€ Rollout 1-1: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 
  â”œâ”€ Rollout 1-2: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘]
  â”œâ”€ Rollout 1-3: [â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘]
  â””â”€ Rollout 1-4: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘]

T1: Batch 1 éƒ¨åˆ†å®Œæˆ â†’ å¼€å§‹è®­ç»ƒ (ä¸ç­‰å¾…å…¨éƒ¨å®Œæˆ)
  â”œâ”€ è®­ç»ƒ GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] è®­ç»ƒ Batch 1 (éƒ¨åˆ†æ•°æ®)
  â””â”€ æ¨ç† GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] ç»§ç»­æ”¶é›† Batch 1 (å‰©ä½™éƒ¨åˆ†)

T2: è®­ç»ƒå®Œæˆï¼Œå¼€å§‹æ”¶é›† Batch 2 (ä½¿ç”¨æ›´æ–°åçš„æ¨¡å‹)
  â”œâ”€ è®­ç»ƒ GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] è®­ç»ƒ Batch 1 (å®Œæ•´æ•°æ®)
  â””â”€ æ¨ç† GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] æ”¶é›† Batch 2

T3: å¹¶è¡Œæ‰§è¡Œ
  â”œâ”€ è®­ç»ƒ GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] è®­ç»ƒ Batch 2
  â””â”€ æ¨ç† GPU: [â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] æ”¶é›† Batch 3 (ä½¿ç”¨æ›´æ–°åçš„æ¨¡å‹)
```

**ä¼˜åŠ¿**ï¼š
- âœ… GPU åˆ©ç”¨ç‡æ¥è¿‘ 100%ï¼šè®­ç»ƒå’Œæ¨ç†åŒæ—¶è¿›è¡Œ
- âœ… è®­ç»ƒé€Ÿåº¦æå‡ 2.57xï¼šä¸ç­‰å¾…æ…¢çš„ rollout
- âœ… æ¨¡å‹æ›´æ–°æ›´åŠæ—¶ï¼šå¯ä»¥ç«‹å³ä½¿ç”¨æ–°æ¨¡å‹å‚æ•°è¿›è¡Œæ¨ç†

---

## äºŒã€AReaL å¼‚æ­¥æ¶æ„è¯¦è§£

### 2.1 æ ¸å¿ƒç»„ä»¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AReaL å¼‚æ­¥è®­ç»ƒç³»ç»Ÿ                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Rollout Workers â”‚      â”‚ Trainer Workers  â”‚             â”‚
â”‚  â”‚  (æ¨ç† GPU)      â”‚â—„â”€â”€â”€â”€â–ºâ”‚ (è®­ç»ƒ GPU)       â”‚             â”‚
â”‚  â”‚                  â”‚      â”‚                  â”‚             â”‚
â”‚  â”‚  - æŒç»­ç”Ÿæˆ      â”‚      â”‚  - æŒç»­è®­ç»ƒ      â”‚             â”‚
â”‚  â”‚  - å¯ä¸­æ–­        â”‚      â”‚  - å‚æ•°æ›´æ–°      â”‚             â”‚
â”‚  â”‚  - åŠ è½½æ–°æƒé‡    â”‚      â”‚  - ä¿å­˜checkpointâ”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                            â”‚                       â”‚
â”‚         â”‚                            â”‚                       â”‚
â”‚         â–¼                            â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  Replay Buffer   â”‚      â”‚  Parameter Store â”‚             â”‚
â”‚  â”‚  (å…±äº«å­˜å‚¨)      â”‚      â”‚  (åˆ†å¸ƒå¼å­˜å‚¨)    â”‚             â”‚
â”‚  â”‚                  â”‚      â”‚                  â”‚             â”‚
â”‚  â”‚  - å­˜å‚¨rollouts  â”‚      â”‚  - å­˜å‚¨æ¨¡å‹å‚æ•°  â”‚             â”‚
â”‚  â”‚  - æŒ‰é™ˆæ—§åº¦è¿‡æ»¤  â”‚      â”‚  - ç‰ˆæœ¬ç®¡ç†      â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â–²                            â–²                       â”‚
â”‚         â”‚                            â”‚                       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                  â”‚                                           â”‚
â”‚                  â–¼                                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚         â”‚ Rollout Controllerâ”‚                                â”‚
â”‚         â”‚ (è°ƒåº¦åè°ƒ)        â”‚                                â”‚
â”‚         â”‚                  â”‚                                â”‚
â”‚         â”‚ - ä»»åŠ¡åˆ†å‘       â”‚                                â”‚
â”‚         â”‚ - æ•°æ®æµæ§åˆ¶     â”‚                                â”‚
â”‚         â”‚ - é™ˆæ—§åº¦æ£€æŸ¥     â”‚                                â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 å¯ä¸­æ–­ç”Ÿæˆæœºåˆ¶ (Interruptible Generation)

è¿™æ˜¯ AReaL çš„æ ¸å¿ƒåˆ›æ–°ï¼

**ä¼ ç»Ÿæ–¹å¼ï¼ˆä¸å¯ä¸­æ–­ï¼‰**ï¼š
```python
# ä¼ ç»ŸåŒæ­¥æ–¹å¼
for rollout in rollouts:
    trajectory = []
    for turn in range(max_turns):
        action = model.generate(state)  # ä½¿ç”¨å›ºå®šæ¨¡å‹
        trajectory.append(action)
        state = env.step(action)
    # åªæœ‰å½“æ‰€æœ‰ rollouts å®Œæˆï¼Œæ‰æ›´æ–°æ¨¡å‹
```

**AReaL å¯ä¸­æ–­æ–¹å¼**ï¼š
```python
# AReaL å¼‚æ­¥æ–¹å¼
class InterruptibleRolloutWorker:
    async def generate_rollout(self, task, model_version):
        trajectory = []
        current_model = self.load_model(model_version)  # åŠ è½½æŒ‡å®šç‰ˆæœ¬çš„æ¨¡å‹
        
        for turn in range(max_turns):
            # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ¨¡å‹ç‰ˆæœ¬
            latest_version = await self.check_model_version()
            if latest_version > model_version:
                # ä¸­æ–­å½“å‰ç”Ÿæˆï¼ŒåŠ è½½æ–°æ¨¡å‹
                current_model = self.load_model(latest_version)
                model_version = latest_version
                logger.info(f"Interrupted: switched to model v{latest_version}")
            
            # ç»§ç»­ç”Ÿæˆï¼ˆä½¿ç”¨æ–°æ¨¡å‹ï¼‰
            action = current_model.generate(state)
            trajectory.append(action)
            state = await env.step(action)
        
        return trajectory, model_version
```

**å…³é”®ç‚¹**ï¼š
1. **æ£€æŸ¥ç‚¹æœºåˆ¶**ï¼šåœ¨æ¯ä¸ª turn æ£€æŸ¥æ¨¡å‹ç‰ˆæœ¬
2. **æ— ç¼åˆ‡æ¢**ï¼šä¸­æ–­åå¯ä»¥æ— ç¼åŠ è½½æ–°æ¨¡å‹ç»§ç»­ç”Ÿæˆ
3. **ç‰ˆæœ¬è¿½è¸ª**ï¼šæ¯ä¸ª rollout è®°å½•ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬

### 2.3 æ•°æ®é™ˆæ—§åº¦æ§åˆ¶ (Staleness Control)

**é—®é¢˜**ï¼šå¦‚æœ rollout ä½¿ç”¨çš„æ˜¯æ—§æ¨¡å‹ï¼Œè®­ç»ƒæ—¶åº”è¯¥å¦‚ä½•å¤„ç†ï¼Ÿ

**AReaL çš„è§£å†³æ–¹æ¡ˆ**ï¼š

```python
class StalenessController:
    def __init__(self, max_staleness=5):
        self.max_staleness = max_staleness  # æœ€å¤§å…è®¸é™ˆæ—§åº¦
    
    def is_valid(self, rollout, current_model_version):
        """
        æ£€æŸ¥ rollout æ˜¯å¦å¯ä»¥ä½¿ç”¨
        
        staleness = current_version - rollout_version
        
        - staleness = 0: ä½¿ç”¨æœ€æ–°æ¨¡å‹ç”Ÿæˆï¼ˆæœ€ä½³ï¼‰
        - 0 < staleness <= max_staleness: å¯ä»¥ä½¿ç”¨ï¼ˆä½†å¯èƒ½å½±å“è®­ç»ƒæ•ˆæœï¼‰
        - staleness > max_staleness: ä¸¢å¼ƒï¼ˆå¤ªæ—§äº†ï¼‰
        """
        staleness = current_model_version - rollout.model_version
        
        if staleness > self.max_staleness:
            return False, f"Too stale: {staleness} > {self.max_staleness}"
        
        return True, f"Staleness: {staleness}"
```

**ç¤ºä¾‹**ï¼š

```
æ—¶é—´çº¿ï¼š

T0: Model v10 ç”Ÿæˆ Rollout A
T1: Model v11 ç”Ÿæˆ Rollout B
T2: Model v12 ç”Ÿæˆ Rollout C
T3: å½“å‰æ¨¡å‹ç‰ˆæœ¬ v15

Rollout A: staleness = 15 - 10 = 5  (å¯ä»¥ä½¿ç”¨ï¼Œå¦‚æœåœ¨ max_staleness=5 å†…)
Rollout B: staleness = 15 - 11 = 4  (å¯ä»¥ä½¿ç”¨)
Rollout C: staleness = 15 - 12 = 3  (å¯ä»¥ä½¿ç”¨)

å¦‚æœ max_staleness=3:
  - Rollout A: âŒ ä¸¢å¼ƒï¼ˆå¤ªæ—§ï¼‰
  - Rollout B: âœ… ä½¿ç”¨
  - Rollout C: âœ… ä½¿ç”¨
```

### 2.4 å®Œæ•´çš„å¼‚æ­¥æµç¨‹

```python
# ä¼ªä»£ç å±•ç¤º AReaL çš„å®Œæ•´æµç¨‹

class AReaLTrainer:
    def __init__(self):
        self.model_version = 0
        self.replay_buffer = ReplayBuffer()
        self.rollout_workers = [RolloutWorker() for _ in range(N_ROLLOUT_WORKERS)]
        self.trainer_workers = [TrainerWorker() for _ in range(N_TRAINER_WORKERS)]
        self.parameter_store = ParameterStore()
    
    async def train(self):
        # 1. å¯åŠ¨æ‰€æœ‰ workerï¼ˆå¹¶è¡Œè¿è¡Œï¼‰
        rollout_tasks = [
            self.rollout_worker_loop(worker) 
            for worker in self.rollout_workers
        ]
        training_tasks = [
            self.training_worker_loop(worker)
            for worker in self.trainer_workers
        ]
        
        # 2. å¹¶è¡Œæ‰§è¡Œ
        await asyncio.gather(*rollout_tasks, *training_tasks)
    
    async def rollout_worker_loop(self, worker):
        """Rollout worker æŒç»­ç”Ÿæˆæ•°æ®"""
        while True:
            # è·å–å½“å‰æ¨¡å‹ç‰ˆæœ¬
            current_version = self.model_version
            
            # ç”Ÿæˆ rolloutï¼ˆå¯ä¸­æ–­ï¼‰
            trajectory, used_version = await worker.generate_interruptible(
                task=random_task(),
                model_version=current_version,
            )
            
            # è®¡ç®—å¥–åŠ±
            reward = await self.compute_reward(trajectory)
            
            # å­˜å‚¨åˆ° replay buffer
            await self.replay_buffer.add(
                trajectory=trajectory,
                reward=reward,
                model_version=used_version,
                timestamp=time.time(),
            )
    
    async def training_worker_loop(self, worker):
        """Training worker æŒç»­è®­ç»ƒ"""
        while True:
            # ä» replay buffer é‡‡æ ·ï¼ˆæŒ‰é™ˆæ—§åº¦è¿‡æ»¤ï¼‰
            batch = await self.replay_buffer.sample(
                batch_size=32,
                max_staleness=5,
                current_version=self.model_version,
            )
            
            # è®­ç»ƒä¸€æ­¥
            loss = await worker.train_step(batch)
            
            # æ›´æ–°æ¨¡å‹ç‰ˆæœ¬
            self.model_version += 1
            
            # ä¿å­˜æ–°å‚æ•°
            await self.parameter_store.save(
                version=self.model_version,
                weights=worker.model.state_dict(),
            )
```

---

## ä¸‰ã€ä¸ç”¨åŠ¨æ€ LoRA æ—¶ï¼ŒAReaL å¦‚ä½•å¸®åŠ©è®­ç»ƒï¼Ÿ

### 3.1 åŠ¨æ€ LoRA vs é™æ€æ¨¡å‹

**åŠ¨æ€ LoRAï¼ˆä½ å½“å‰çš„æ–¹å¼ï¼‰**ï¼š
```python
# è®­ç»ƒè¿‡ç¨‹ä¸­åŠ¨æ€åˆ‡æ¢ LoRA é€‚é…å™¨
for step in range(max_steps):
    # 1. ä½¿ç”¨å½“å‰ LoRA æ”¶é›† rollouts
    rollouts = collect_rollouts(model_with_lora_v1)
    
    # 2. è®­ç»ƒ LoRAï¼Œå¾—åˆ°æ–°ç‰ˆæœ¬
    train_step()
    model_with_lora_v2 = get_updated_lora()
    
    # 3. é€šçŸ¥ vLLM åŠ è½½æ–° LoRA
    vllm.load_lora_adapter("path/to/lora_v2")
    
    # 4. ä½¿ç”¨æ–° LoRA æ”¶é›†ä¸‹ä¸€æ‰¹ rollouts
    rollouts = collect_rollouts(model_with_lora_v2)
```

**é™æ€æ¨¡å‹ï¼ˆä¸ç”¨åŠ¨æ€ LoRAï¼‰**ï¼š
```python
# é€‰é¡¹ A: å…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-tuningï¼‰
model = load_model()  # åŠ è½½å®Œæ•´æ¨¡å‹

for step in range(max_steps):
    rollouts = collect_rollouts(model)  # ä½¿ç”¨å½“å‰æ¨¡å‹
    train_step(model)  # æ›´æ–°å…¨éƒ¨å‚æ•°
    # æ¨¡å‹å‚æ•°å·²ç»æ›´æ–°ï¼Œä¸‹æ¬¡ rollout è‡ªåŠ¨ä½¿ç”¨æ–°å‚æ•°

# é€‰é¡¹ B: é™æ€ LoRAï¼ˆè®­ç»ƒæ—¶ä¸åˆ‡æ¢ï¼‰
model = load_model()
lora = create_lora_adapter()

for step in range(max_steps):
    # å§‹ç»ˆä½¿ç”¨åŒä¸€ä¸ª LoRA é€‚é…å™¨
    rollouts = collect_rollouts(model, lora)
    train_step(lora)  # åªæ›´æ–° LoRA å‚æ•°
    # ä½†æ¨ç†æ—¶ä¸ç”¨é‡æ–°åŠ è½½ï¼ˆå› ä¸º LoRA å·²ç» attach åˆ°æ¨¡å‹ï¼‰
```

### 3.2 AReaL å¯¹ä¸¤ç§æ–¹å¼çš„æ”¯æŒ

#### æ–¹å¼ 1: å…¨å‚æ•°å¾®è°ƒï¼ˆFull Fine-tuningï¼‰

**AReaL å¦‚ä½•å¤„ç†**ï¼š

```python
# AReaL é…ç½®ï¼ˆå…¨å‚æ•°å¾®è°ƒï¼‰
config = {
    "model": {
        "name": "Qwen3-VL-32B",
        "trainable_params": "all",  # è®­ç»ƒæ‰€æœ‰å‚æ•°
        "use_lora": False,
    },
    "training": {
        "method": "full_finetuning",
        # ...
    }
}

# AReaL å†…éƒ¨å¤„ç†
class AReaLTrainer:
    def __init__(self, config):
        # åŠ è½½å®Œæ•´æ¨¡å‹
        self.model = load_model(config.model.name)
        
        # ä¸ä½¿ç”¨ LoRA
        # self.model = apply_lora(self.model)  # è·³è¿‡è¿™ä¸€æ­¥
    
    async def training_step(self, batch):
        # ç›´æ¥æ›´æ–°æ¨¡å‹çš„æ‰€æœ‰å‚æ•°
        loss = compute_loss(self.model, batch)
        loss.backward()
        optimizer.step()
        
        # æ¨¡å‹å‚æ•°å·²ç»æ›´æ–°ï¼Œä¸‹æ¬¡ rollout è‡ªåŠ¨ä½¿ç”¨æ–°å‚æ•°
        self.model_version += 1
        await self.save_checkpoint(self.model_version)
```

**ä¼˜åŠ¿**ï¼š
- âœ… **æ›´ç®€å•**ï¼šä¸éœ€è¦å¤„ç† LoRA åŠ è½½/å¸è½½
- âœ… **æ€§èƒ½å¯èƒ½æ›´å¥½**ï¼šå…¨å‚æ•°æ›´æ–°é€šå¸¸æ•ˆæœæ›´å¥½
- âœ… **AReaL åŸç”Ÿæ”¯æŒ**ï¼šä¸éœ€è¦ç‰¹æ®Šå¤„ç†

**åŠ£åŠ¿**ï¼š
- âŒ **å†…å­˜å ç”¨å¤§**ï¼šéœ€è¦å­˜å‚¨æ‰€æœ‰å‚æ•°çš„æ¢¯åº¦
- âŒ **è®­ç»ƒæ…¢**ï¼šæ›´æ–°æ‰€æœ‰å‚æ•°æ¯”åªæ›´æ–° LoRA æ…¢
- âŒ **éœ€è¦æ›´å¤š GPU**ï¼šå¯èƒ½éœ€è¦æ›´å¤§çš„æ˜¾å­˜

#### æ–¹å¼ 2: é™æ€ LoRAï¼ˆè®­ç»ƒæ—¶ä¸åŠ¨æ€åˆ‡æ¢ï¼‰

**AReaL å¦‚ä½•å¤„ç†**ï¼š

```python
# AReaL é…ç½®ï¼ˆé™æ€ LoRAï¼‰
config = {
    "model": {
        "name": "Qwen3-VL-32B",
        "use_lora": True,
        "lora_config": {
            "r": 16,
            "alpha": 32,
            # ...
        },
        "dynamic_lora": False,  # å…³é”®ï¼šä¸ä½¿ç”¨åŠ¨æ€åˆ‡æ¢
    }
}

# AReaL å†…éƒ¨å¤„ç†
class AReaLTrainer:
    def __init__(self, config):
        # åŠ è½½æ¨¡å‹å¹¶åº”ç”¨ LoRAï¼ˆä¸€æ¬¡æ€§ï¼‰
        self.model = load_model(config.model.name)
        self.model = apply_lora(self.model, config.model.lora_config)
        
        # LoRA å‚æ•°å·²ç» attach åˆ°æ¨¡å‹
        # ä¸éœ€è¦åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡æ–°åŠ è½½
    
    async def training_step(self, batch):
        # åªæ›´æ–° LoRA å‚æ•°ï¼ˆæ¨¡å‹çš„å…¶ä»–å‚æ•°å†»ç»“ï¼‰
        loss = compute_loss(self.model, batch)
        loss.backward()  # åªæœ‰ LoRA å‚æ•°æœ‰æ¢¯åº¦
        optimizer.step()  # åªæ›´æ–° LoRA å‚æ•°
        
        # LoRA å‚æ•°å·²ç»æ›´æ–°ï¼ˆattach åœ¨æ¨¡å‹ä¸Šï¼‰
        # ä¸‹æ¬¡ rollout è‡ªåŠ¨ä½¿ç”¨æ–°çš„ LoRA å‚æ•°
        self.model_version += 1
        await self.save_checkpoint(self.model_version, lora_only=True)
```

**å…³é”®ç‚¹**ï¼š
- LoRA å‚æ•°**attach åœ¨æ¨¡å‹ä¸Š**ï¼Œè®­ç»ƒæ—¶ç›´æ¥æ›´æ–°
- ä¸éœ€è¦"å¸è½½æ—§ LoRAï¼ŒåŠ è½½æ–° LoRA"çš„è¿‡ç¨‹
- AReaL çš„å¼‚æ­¥æœºåˆ¶ä»ç„¶æœ‰æ•ˆ

### 3.3 æ¨ç†æ—¶çš„æ¨¡å‹åŒæ­¥

**é—®é¢˜**ï¼šå¦‚æœ rollout worker å’Œ trainer worker ä½¿ç”¨ä¸åŒçš„ GPUï¼Œå¦‚ä½•åŒæ­¥æ¨¡å‹ï¼Ÿ

**AReaL çš„è§£å†³æ–¹æ¡ˆ**ï¼š

```python
class AReaLRolloutWorker:
    def __init__(self, parameter_store):
        self.parameter_store = parameter_store
        self.model = None
        self.model_version = -1
    
    async def load_latest_model(self):
        """åŠ è½½æœ€æ–°ç‰ˆæœ¬çš„æ¨¡å‹å‚æ•°"""
        latest_version = await self.parameter_store.get_latest_version()
        
        if latest_version > self.model_version:
            # åŠ è½½æ–°å‚æ•°
            if self.use_lora:
                # åªåŠ è½½ LoRA å‚æ•°ï¼ˆæ›´è½»é‡ï¼‰
                lora_weights = await self.parameter_store.load_lora(latest_version)
                self.model.load_lora_weights(lora_weights)
            else:
                # åŠ è½½å…¨éƒ¨å‚æ•°
                weights = await self.parameter_store.load_weights(latest_version)
                self.model.load_state_dict(weights)
            
            self.model_version = latest_version
            logger.info(f"Loaded model version {latest_version}")
    
    async def generate_with_interruption(self, task):
        """å¯ä¸­æ–­ç”Ÿæˆ"""
        trajectory = []
        
        for turn in range(max_turns):
            # æ£€æŸ¥å¹¶åŠ è½½æ–°æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            await self.load_latest_model()
            
            # ç”ŸæˆåŠ¨ä½œï¼ˆä½¿ç”¨å½“å‰æ¨¡å‹ç‰ˆæœ¬ï¼‰
            action = self.model.generate(state)
            trajectory.append(action)
            state = await env.step(action)
        
        return trajectory, self.model_version
```

**ä¸¤ç§æ¨¡å¼çš„åŒæ­¥**ï¼š

**å…¨å‚æ•°å¾®è°ƒ**ï¼š
```python
# Trainer æ›´æ–°æ‰€æœ‰å‚æ•°
trainer.model.weight.data += gradient * lr  # æ›´æ–°æ‰€æœ‰å‚æ•°

# Rollout Worker éœ€è¦åŠ è½½å®Œæ•´æ¨¡å‹
rollout_worker.model.load_state_dict(trainer.model.state_dict())  # åŒæ­¥æ‰€æœ‰å‚æ•°
```

**é™æ€ LoRA**ï¼š
```python
# Trainer åªæ›´æ–° LoRA å‚æ•°
trainer.model.lora_A.data += gradient * lr  # åªæ›´æ–° LoRA

# Rollout Worker åªéœ€è¦åŠ è½½ LoRA å‚æ•°ï¼ˆæ›´è½»é‡ï¼ï¼‰
rollout_worker.model.load_lora_weights(trainer.model.get_lora_weights())  # åªåŒæ­¥ LoRA
```

### 3.4 AReaL å¸¦æ¥çš„å¥½å¤„ï¼ˆå³ä½¿ä¸ç”¨åŠ¨æ€ LoRAï¼‰

å³ä½¿ä¸ä½¿ç”¨åŠ¨æ€ LoRAï¼ŒAReaL ä»ç„¶å¸¦æ¥å·¨å¤§ä»·å€¼ï¼š

#### 1. **å¼‚æ­¥è®­ç»ƒæ¶æ„**

```python
# ä½ çš„å½“å‰æ–¹å¼ï¼ˆåŒæ­¥ï¼‰
rollouts = await collect_all_rollouts()  # ç­‰å¾…æ‰€æœ‰å®Œæˆ
train_step(rollouts)  # ç„¶åè®­ç»ƒ

# AReaL æ–¹å¼ï¼ˆå¼‚æ­¥ï¼‰
# Rollout å’Œè®­ç»ƒå¹¶è¡Œè¿›è¡Œï¼Œä¸äº’ç›¸ç­‰å¾…
```

#### 2. **å¯ä¸­æ–­ç”Ÿæˆ**

```python
# å³ä½¿ä¸ç”¨åŠ¨æ€ LoRAï¼Œä»ç„¶å¯ä»¥ä¸­æ–­ç”Ÿæˆä½¿ç”¨æ–°æ¨¡å‹å‚æ•°
# è¿™å¯¹å…¨å‚æ•°å¾®è°ƒç‰¹åˆ«æœ‰ç”¨
```

#### 3. **æ•°æ®é™ˆæ—§åº¦æ§åˆ¶**

```python
# è‡ªåŠ¨è¿‡æ»¤å¤ªæ—§çš„æ•°æ®ï¼Œä¿è¯è®­ç»ƒç¨³å®šæ€§
```

#### 4. **åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ**

```python
# è‡ªåŠ¨å¤„ç†å¤š GPUã€å¤šèŠ‚ç‚¹çš„è®­ç»ƒ
# ä½ ä¸éœ€è¦æ‰‹åŠ¨ç®¡ç†æ•°æ®å¹¶è¡Œã€æ¨¡å‹å¹¶è¡Œ
```

#### 5. **æ€§èƒ½ä¼˜åŒ–**

```python
# å†…ç½®çš„æ€§èƒ½ä¼˜åŒ–ï¼š
# - åºåˆ—æ‰“åŒ…ï¼ˆSequence Packingï¼‰
# - Flash Attention
# - æ¢¯åº¦æ£€æŸ¥ç‚¹
# - æ··åˆç²¾åº¦è®­ç»ƒ
```

---

## å››ã€å…·ä½“ä»£ç ç¤ºä¾‹

### 4.1 ä½¿ç”¨ AReaL è¿›è¡Œå…¨å‚æ•°å¾®è°ƒ

```python
# train_with_areal_full_finetuning.py

from areal.trainer import GRPOTrainer
from areal.config import GRPOConfig
from cua_agent.areal_env import GBoxAReaLEnv

# é…ç½®ï¼ˆå…¨å‚æ•°å¾®è°ƒï¼‰
config = GRPOConfig.from_yaml("config_full_finetuning.yaml")
# config.yaml:
# model:
#   use_lora: false  # ä¸ä½¿ç”¨ LoRA
#   trainable_params: "all"

# åŠ è½½æ¨¡å‹ï¼ˆä¸ä½¿ç”¨ LoRAï¼‰
from transformers import AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained(config.model.name)
tokenizer = AutoTokenizer.from_pretrained(config.model.name)

# åˆ›å»ºç¯å¢ƒ
env = GBoxAReaLEnv(config.rollout)

# åˆ›å»º trainerï¼ˆAReaL ä¼šè‡ªåŠ¨å¤„ç†å¼‚æ­¥ï¼‰
trainer = GRPOTrainer(
    model=model,
    tokenizer=tokenizer,
    env=env,
    config=config,
)

# è®­ç»ƒï¼ˆAReaL å†…éƒ¨ä¼šè‡ªåŠ¨ï¼š
# 1. å¯åŠ¨å¼‚æ­¥ rollout workers
# 2. å¯åŠ¨å¼‚æ­¥ training workers
# 3. å¤„ç†æ¨¡å‹å‚æ•°åŒæ­¥
# 4. å¤„ç†æ•°æ®é™ˆæ—§åº¦
# 5. å¤„ç† checkpoint ä¿å­˜ï¼‰
trainer.train()
```

### 4.2 ä½¿ç”¨ AReaL è¿›è¡Œé™æ€ LoRA è®­ç»ƒ

```python
# train_with_areal_static_lora.py

from areal.trainer import GRPOTrainer
from areal.config import GRPOConfig
from peft import LoraConfig, get_peft_model

# é…ç½®ï¼ˆé™æ€ LoRAï¼‰
config = GRPOConfig.from_yaml("config_static_lora.yaml")
# config.yaml:
# model:
#   use_lora: true
#   dynamic_lora: false  # å…³é”®ï¼šä¸ä½¿ç”¨åŠ¨æ€åˆ‡æ¢
#   lora:
#     r: 16
#     alpha: 32

# åŠ è½½æ¨¡å‹å¹¶åº”ç”¨ LoRAï¼ˆä¸€æ¬¡æ€§ï¼‰
model = AutoModelForCausalLM.from_pretrained(config.model.name)
lora_config = LoraConfig(
    r=config.lora.r,
    alpha=config.lora.alpha,
    target_modules=config.lora.target_modules,
)
model = get_peft_model(model, lora_config)
# LoRA å·²ç» attach åˆ°æ¨¡å‹ï¼Œä¸éœ€è¦åŠ¨æ€åˆ‡æ¢

# åˆ›å»º trainer
trainer = GRPOTrainer(
    model=model,
    tokenizer=tokenizer,
    env=env,
    config=config,
)

# è®­ç»ƒï¼ˆAReaL ä¼šï¼š
# 1. å¼‚æ­¥æ”¶é›† rolloutsï¼ˆä½¿ç”¨ attach çš„ LoRAï¼‰
# 2. è®­ç»ƒæ—¶åªæ›´æ–° LoRA å‚æ•°
# 3. LoRA å‚æ•°è‡ªåŠ¨åŒæ­¥åˆ° rollout workersï¼ˆå› ä¸ºå·²ç» attachï¼‰
trainer.train()
```

---

## äº”ã€å¯¹æ¯”æ€»ç»“

### 5.1 ä¸‰ç§æ–¹å¼çš„å¯¹æ¯”

| ç‰¹æ€§ | ä½ çš„å½“å‰æ–¹å¼<br>(åŠ¨æ€ LoRA) | å…¨å‚æ•°å¾®è°ƒ<br>(AReaL) | é™æ€ LoRA<br>(AReaL) |
|------|---------------------------|---------------------|---------------------|
| **LoRA åˆ‡æ¢** | âœ… éœ€è¦åŠ¨æ€åŠ è½½/å¸è½½ | âŒ ä¸é€‚ç”¨ | âŒ ä¸éœ€è¦ï¼ˆå·² attachï¼‰ |
| **å†…å­˜å ç”¨** | ğŸŸ¢ ä½ï¼ˆåªå­˜ LoRAï¼‰ | ğŸ”´ é«˜ï¼ˆå­˜æ‰€æœ‰å‚æ•°ï¼‰ | ğŸŸ¢ ä½ï¼ˆåªå­˜ LoRAï¼‰ |
| **è®­ç»ƒé€Ÿåº¦** | ğŸŸ¢ å¿«ï¼ˆåªæ›´æ–° LoRAï¼‰ | ğŸ”´ æ…¢ï¼ˆæ›´æ–°æ‰€æœ‰ï¼‰ | ğŸŸ¢ å¿«ï¼ˆåªæ›´æ–° LoRAï¼‰ |
| **æ¨¡å‹æ€§èƒ½** | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¢ æœ€å¥½ | ğŸŸ¡ ä¸­ç­‰ |
| **AReaL æ”¯æŒ** | âš ï¸ éœ€è¦é€‚é… | âœ… åŸç”Ÿæ”¯æŒ | âœ… åŸç”Ÿæ”¯æŒ |
| **å¼‚æ­¥ä¼˜åŠ¿** | âœ… å¯ä»¥äº«å— | âœ… å¯ä»¥äº«å— | âœ… å¯ä»¥äº«å— |
| **å¤æ‚åº¦** | ğŸ”´ é«˜ï¼ˆéœ€å¤„ç†åˆ‡æ¢ï¼‰ | ğŸŸ¢ ä½ï¼ˆç®€å•ï¼‰ | ğŸŸ¢ ä½ï¼ˆç®€å•ï¼‰ |

### 5.2 æ¨èæ–¹æ¡ˆ

**å¦‚æœä½ æƒ³ç®€åŒ–ä»£ç **ï¼š
- âœ… **ä½¿ç”¨é™æ€ LoRA**ï¼ˆæ–¹å¼ 2ï¼‰
  - äº«å— AReaL çš„å¼‚æ­¥ä¼˜åŠ¿
  - ä¸éœ€è¦å¤„ç†åŠ¨æ€åˆ‡æ¢
  - ä»£ç æ›´ç®€å•

**å¦‚æœä½ æƒ³è¦æœ€ä½³æ€§èƒ½**ï¼š
- âœ… **ä½¿ç”¨å…¨å‚æ•°å¾®è°ƒ**ï¼ˆæ–¹å¼ 1ï¼‰
  - æ€§èƒ½é€šå¸¸æœ€å¥½
  - AReaL åŸç”Ÿæ”¯æŒ
  - éœ€è¦æ›´å¤š GPU å†…å­˜

**å¦‚æœä½ å·²ç»å®ç°äº†åŠ¨æ€ LoRA**ï¼š
- âš ï¸ **å¯ä»¥ä¿ç•™**ï¼Œä½†éœ€è¦é€‚é… AReaL çš„æ¥å£
- æˆ–è€…**è¿ç§»åˆ°é™æ€ LoRA**ï¼Œä»£ç æ›´ç®€å•

---

## å…­ã€å…³é”®è¦ç‚¹æ€»ç»“

1. **AReaL çš„å¼‚æ­¥æœºåˆ¶ä¸ä¾èµ–äºåŠ¨æ€ LoRA**
   - å¼‚æ­¥æ¶æ„é€‚ç”¨äºä»»ä½•è®­ç»ƒæ–¹å¼
   - å…¨å‚æ•°å¾®è°ƒå’Œé™æ€ LoRA éƒ½èƒ½äº«å—å¼‚æ­¥ä¼˜åŠ¿

2. **å¯ä¸­æ–­ç”Ÿæˆæ˜¯æ ¸å¿ƒåˆ›æ–°**
   - å…è®¸åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åˆ‡æ¢åˆ°æ–°æ¨¡å‹
   - å¯¹å…¨å‚æ•°å¾®è°ƒç‰¹åˆ«æœ‰ç”¨

3. **æ•°æ®é™ˆæ—§åº¦æ§åˆ¶ä¿è¯è®­ç»ƒç¨³å®šæ€§**
   - è‡ªåŠ¨è¿‡æ»¤å¤ªæ—§çš„æ•°æ®
   - é˜²æ­¢ä½¿ç”¨è¿‡æ—¶çš„æ¨¡å‹ç”Ÿæˆçš„æ•°æ®è®­ç»ƒ

4. **é™æ€ LoRA æ›´ç®€å•**
   - ä¸éœ€è¦åŠ¨æ€åŠ è½½/å¸è½½
   - LoRA å‚æ•° attach åœ¨æ¨¡å‹ä¸Šï¼Œè‡ªåŠ¨åŒæ­¥
   - æ¨èç”¨äºç®€åŒ–ä»£ç 

5. **AReaL çš„ä»·å€¼ä¸ä»…åœ¨äºåŠ¨æ€ LoRA**
   - å¼‚æ­¥è®­ç»ƒæ¶æ„
   - åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
   - æ€§èƒ½ä¼˜åŒ–
   - è¿™äº›éƒ½ä¸ä¾èµ–äºåŠ¨æ€ LoRA

---

**ç»“è®º**ï¼šå³ä½¿ä¸ä½¿ç”¨åŠ¨æ€ LoRAï¼ŒAReaL ä»ç„¶èƒ½å¸¦æ¥å·¨å¤§çš„ä»·å€¼ï¼Œä¸»è¦ä½“ç°åœ¨å¼‚æ­¥è®­ç»ƒæ¶æ„å’Œæ€§èƒ½ä¼˜åŒ–ä¸Šã€‚å»ºè®®ä½¿ç”¨é™æ€ LoRA æˆ–å…¨å‚æ•°å¾®è°ƒï¼Œäº«å— AReaL çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶ç®€åŒ–ä»£ç ã€‚

