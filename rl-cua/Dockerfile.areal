# Dockerfile.areal
# 基于 AReaL 官方 Dockerfile: https://github.com/inclusionAI/AReaL/blob/main/Dockerfile
# 添加项目特定的依赖和配置

FROM lmsysorg/sglang:v0.5.5.post1-cu129-amd64 AS base

WORKDIR /workspace

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates \
    net-tools \
    kmod \
    ccache \
    libibverbs-dev \
    librdmacm-dev \
    ibverbs-utils \
    rdmacm-utils \
    python3-pyverbs \
    opensm \
    ibutils \
    perftest \
    python3-venv \
    tmux \
    lsof \
    nvtop \
    git \
    curl \
    vim \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Update pip and install uv
RUN pip install -U pip "setuptools<80,>=77.0.3" uv

# Environment variables for build configuration
ENV NVTE_WITH_USERBUFFERS=1
ENV NVTE_FRAMEWORK=pytorch
ENV MPI_HOME=/usr/local/mpi
ENV TORCH_CUDA_ARCH_LIST="8.0 8.9 9.0 9.0a"
ENV MAX_JOBS=32

##############################################################
# The following block is adapted from slime's Dockerfile
# https://github.com/THUDM/slime/blob/ebf16c57c223d6f1f66ef89177d5e27938c6caaf/docker/Dockerfile

# Install torch memory saver
RUN uv pip install --no-build-isolation --system --no-cache-dir --force-reinstall \
    git+https://github.com/fzyzcjy/torch_memory_saver.git

# Install grouped_gemm
RUN uv pip install --no-build-isolation --system \
    git+https://github.com/fanshiqing/grouped_gemm@v1.1.4

# Install apex
RUN NVCC_APPEND_FLAGS="--threads 4" \
    pip -v install --disable-pip-version-check --no-cache-dir --no-build-isolation \
    --config-settings "--build-option=--cpp_ext --cuda_ext --parallel 8" \
    git+https://github.com/NVIDIA/apex.git

# Install transformer engine (with --no-deps to avoid installing torch and torch-extensions)
RUN pip install nvidia-mathdx pybind11 \
    && pip -v install --no-build-isolation \
    git+https://github.com/NVIDIA/TransformerEngine.git@stable

# Install flash attention (v2.8.1 is the latest version that megatron supports)
RUN uv pip -v install flash-attn==2.8.1 --no-build-isolation --system
##############################################################

# Install flash-attn3
RUN git clone https://github.com/Dao-AILab/flash-attention -b v2.8.1 \
    && uv pip install -v /flash-attention/hopper/ --no-build-isolation --system \
    && mkdir -p /usr/local/lib/python3.12/dist-packages/flash_attn_3/ \
    && cp /flash-attention/hopper/flash_attn_interface.py /usr/local/lib/python3.12/dist-packages/flash_attn_3/ \
    && rm -rf /flash-attention

# Misc fixes
RUN uv pip uninstall pynvml --system
# Update setuptools to fix a wandb bug
# Install nvidia-ml-py to replace pynvml
RUN uv pip install -U setuptools nvidia-ml-py --system

# Remove libcudnn9 to avoid conflicts with torch
RUN apt-get --purge remove -y --allow-change-held-packages libcudnn9* \
    && apt-get autoremove -y \
    && rm -rf /var/lib/apt/lists/*

# ============ 安装 AReaL ============
# 从本地源码安装 AReaL（与官方 Dockerfile 一致）
# 构建上下文应该是 AReaL 根目录，所以这里复制整个 AReaL 源码
COPY . /AReaL

# Install AReaL from local source
# Avoid overwriting flash-attn by omitting the `[fa]` extra
RUN cd /AReaL \
    && uv pip install -e ".[dev,docs,vllm,sglang]" --system

# ============ 安装项目特定依赖 ============
# 注意：AReaL 已经包含了大部分依赖（transformers, datasets, wandb, tqdm, pydantic, 
# httpx, aiohttp, tenacity, peft 等），这里只安装额外的依赖
# 如果需要更新版本或添加新依赖，请按照 AReaL 的方式直接在这里添加

# 安装额外的依赖（如果 AReaL 未包含或需要特定版本）
RUN uv pip install --no-build-isolation --system --no-cache-dir \
    safetensors>=0.4.5 \
    Pillow>=10.4.0 \
    python-dotenv>=1.0.1

# ============ 安装 GBox ============
RUN uv pip install --no-build-isolation --system --no-cache-dir \
    git+https://github.com/babelcloud/gbox-cua.git

# ============ 复制项目代码 ============
# 复制 rl-cua 项目代码到工作目录
COPY rl-cua /workspace

# ============ 入口点 ============
ENTRYPOINT ["python"]
CMD ["train_areal.py", "--config", "configs/cua_grpo.yaml"]
