# configs/cua_grpo.yaml
# CUA Agent GRPO 训练配置

# ============ Launcher 配置 ============
launcher:
  type: "local"  # 或 "ray" 用于多节点
  num_gpus: null  # null 表示自动检测所有可用 GPU

# ============ 模型配置 ============
model:
  name: "Qwen/Qwen3-VL-32B-Instruct"  # 使用官方模型名（非 unsloth）
  max_seq_length: 16384
  torch_dtype: "bfloat16"
  trust_remote_code: true
  
  # LoRA 配置（静态 LoRA）
  use_lora: true
  lora:
    r: 16
    alpha: 32
    dropout: 0.0
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    bias: "none"
    task_type: "CAUSAL_LM"

# ============ 训练配置 ============
training:
  # 基础参数
  learning_rate: 1.0e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  
  # 批次配置
  batch_size: 4  # 每 GPU 的任务数
  gradient_accumulation_steps: 4
  
  # 训练进度
  max_steps: 200
  warmup_steps: 10
  
  # 评估和保存
  eval_steps: 10
  save_steps: 10
  save_total_limit: 5
  
  # 最佳模型
  load_best_model_at_end: true
  metric_for_best_model: "eval/accuracy"
  greater_is_better: true
  
  # 早停
  early_stopping_patience: 5
  target_accuracy: 0.90
  
  # 输出
  output_dir: "outputs/grpo_cua"
  seed: 42

# ============ GRPO 算法配置 ============
grpo:
  beta: 0.01  # KL 惩罚系数
  clip_epsilon: 0.2  # PPO clip 参数
  min_group_std: 0.05  # 最小组标准差
  advantage_normalization: true

# ============ Rollout 配置 ============
rollout:
  # 基础参数
  num_rollouts: 4  # 每个任务的 rollout 数量（GRPO 组大小）
  max_turns: 15  # 每个 rollout 的最大回合数
  
  # 并发
  concurrency: 4  # 并行 rollout 数量
  
  # 异步配置
  async_mode: true
  interruptible: true  # 可中断生成
  
  # 数据陈旧度控制
  max_staleness: 5  # 最大允许陈旧度
  
  # 温度变化（用于探索）
  enable_temperature_variation: true
  base_temperature: 0.6
  temperature_increment: 0.1
  
  # 环境配置
  gbox:
    box_type: "android"
    timeout: "60s"
    expires_in: "15m"
  
  # 延迟
  action_delay: 0.5
  screenshot_delay: 0.3

# ============ 推理配置 ============
inference:
  backend: "vllm"  # 或 "sglang"
  
  vllm:
    api_base: "http://localhost:8000/v1"
    max_tokens: 2048
    temperature: 0.7
    top_p: 0.9
    timeout: 120.0
    max_retries: 3

# ============ 分布式训练配置 ============
distributed:
  backend: "fsdp"  # 使用 FSDP
  
  fsdp:
    sharding_strategy: "FULL_SHARD"
    mixed_precision: "bf16"
    gradient_clipping: 1.0
    cpu_offload: false
    
  # 让 FSDP 自动处理设备分配
  # 不需要手动指定 GPU

# ============ 日志和监控 ============
logging:
  level: "INFO"
  log_to_file: true
  log_file: "outputs/grpo_cua/logs/training.log"
  enable_detailed_logging: true
  detailed_log_file: "outputs/grpo_cua/logs/rollouts.log"

monitoring:
  enable_wandb: false
  wandb_project: "cua-grpo"
  wandb_entity: null  # 可选
  enable_tensorboard: false

# ============ Checkpoint 配置 ============
checkpoint:
  resume_from_checkpoint: null  # 或指定路径
  ignore_data_skip: false

