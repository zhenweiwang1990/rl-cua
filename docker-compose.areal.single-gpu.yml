# docker-compose.areal.single-gpu.yml
# AReaL GRPO 训练 Docker Compose 配置 - 单 GPU (H200) 优化版

# version: '3.8'  # Docker Compose v2 不再需要 version 字段

services:
  # ============ AReaL 训练服务 ============
  # 注意：vLLM 服务由 AReal 内置管理（allocation_mode: vllm:d1p1t1+d1p1t1）
  # 不需要独立的 vLLM 容器
  trainer:
    build:
      context: .
      dockerfile: Dockerfile.areal
    
    container_name: areal-cua-trainer-single
    
    # 使用单个 GPU（vLLM 由 AReal 内置管理）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    volumes:
      - .:/workspace
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./outputs:/workspace/outputs
    
    environment:
      # GBox API（必需）
      - GBOX_API_KEY=${GBOX_API_KEY}
      - GBOX_MODEL=${GBOX_MODEL:-gbox-handy-1}
      
      # HuggingFace / Wandb
      - HF_TOKEN=${HF_TOKEN:-}
      - WANDB_API_KEY=${WANDB_API_KEY:-}
      
      # 训练配置
      - CONFIG_FILE=${CONFIG_FILE:-configs/cua_grpo_single_gpu.yaml}
      
      # CUA Agent 配置
      - CUA_MAX_TURNS=${CUA_MAX_TURNS:-15}
      - CUA_CONTEXT_WINDOW=${CUA_CONTEXT_WINDOW:-5}
      
      # CUDA 配置
      - CUDA_VISIBLE_DEVICES=0
      - CUDA_DEVICE_ORDER=PCI_BUS_ID
      - NCCL_DEBUG=INFO
      
      # PyTorch 内存优化
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
      
      # 分布式训练
      - MASTER_ADDR=localhost
      - MASTER_PORT=29500
    
    # 注意：不再依赖独立的 vLLM 服务，vLLM 由 AReal 内置管理
    
    command: >
      -m areal.launcher.local
      train_areal.py
      --config /workspace/${CONFIG_FILE:-configs/cua_grpo_single_gpu.yaml}
    
    restart: "no"
    
    # 允许共享内存
    shm_size: '8gb'
    
    # 网络配置
    ipc: host

