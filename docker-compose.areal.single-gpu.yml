# docker-compose.areal.single-gpu.yml
# AReaL GRPO 训练 Docker Compose 配置 - 单 GPU (H200) 优化版

# version: '3.8'  # Docker Compose v2 不再需要 version 字段

services:
  # ============ AReaL 训练服务 ============
  # 注意：vLLM 服务由 AReal 内置管理（allocation_mode: vllm:d1p1t1+d1p1t1）
  # 不需要独立的 vLLM 容器
  trainer:
    build:
      context: .
      dockerfile: Dockerfile.areal
    
    container_name: areal-cua-trainer-single
    
    # 使用单个 GPU（vLLM 由 AReal 内置管理）
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    
    volumes:
      - .:/workspace
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ./outputs:/workspace/outputs
    
    environment:
      - GBOX_API_KEY=${GBOX_API_KEY}
      - HF_TOKEN=${HF_TOKEN:-}
      - WANDB_API_KEY=${WANDB_API_KEY:-}
      - CONFIG_FILE=${CONFIG_FILE:-configs/cua_grpo_single_gpu.yaml}
      # 注意：vLLM API 由 AReal 内置管理，不需要外部 VLLM_API_BASE
      # 单 GPU 训练环境变量
      - CUDA_VISIBLE_DEVICES=0
      - NCCL_DEBUG=INFO
      # PyTorch 内存优化：使用可扩展段减少内存碎片
      - PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
    
    # 注意：不再依赖独立的 vLLM 服务，vLLM 由 AReal 内置管理
    
    command: >
      -m areal.launcher.local
      train_areal.py
      --config /workspace/${CONFIG_FILE:-configs/cua_grpo_single_gpu.yaml}
    
    restart: "no"
    
    # 允许共享内存
    shm_size: '8gb'
    
    # 网络配置
    ipc: host

