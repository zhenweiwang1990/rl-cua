# CUA Agent Environment Configuration

# GBox API Key (required)
# Get your API key from https://gbox.ai
GBOX_API_KEY=your_gbox_api_key_here

# vLLM Server URL (optional)
# If not set, the agent will load the model locally
# For server mode, start vLLM with ./scripts/run_vllm_base.sh
VLLM_API_BASE=http://localhost:8000/v1

# Model name (default: unsloth/Qwen3-VL-32B-Instruct)
MODEL_NAME=unsloth/Qwen3-VL-32B-Instruct

# Box type (default: android)
BOX_TYPE=android

# Maximum turns (default: 20)
MAX_TURNS=20

# ========================================
# Model Hub Configuration
# ========================================

# Model hub to use: "huggingface" or "modelscope"
# ModelScope is faster for users in China
MODEL_HUB=huggingface

# Hugging Face mirror (for China users)
# Default: https://hf-mirror.com
# Original: https://huggingface.co
HF_ENDPOINT=https://hf-mirror.com

# ModelScope cache directory (when using MODEL_HUB=modelscope)
MODELSCOPE_CACHE=$HOME/.cache/modelscope

