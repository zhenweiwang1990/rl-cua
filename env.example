# CUA Agent Environment Configuration

# GBox API Key (required)
# Get your API key from https://gbox.ai
GBOX_API_KEY=your_gbox_api_key_here

# ========================================
# VLM Provider Configuration
# ========================================

# VLM Provider: "vllm" or "openrouter" (default: vllm)
# - "vllm": Use local vLLM server or load model locally
# - "openrouter": Use OpenRouter API (requires OPENROUTER_API_KEY)
VLM_PROVIDER=vllm

# vLLM Server URL (optional, used when VLM_PROVIDER=vllm)
# If not set, the agent will load the model locally
# For server mode, start vLLM with ./scripts/run_vllm_base.sh
VLLM_API_BASE=http://localhost:8000/v1

# OpenRouter API Key (required when VLM_PROVIDER=openrouter)
# Get your API key from https://openrouter.ai
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter API Base URL (optional, default: https://openrouter.ai/api/v1)
OPENROUTER_API_BASE=https://openrouter.ai/api/v1

# Model name (default: unsloth/Qwen3-VL-30B-A3B-Instruct)
# For OpenRouter, the model will be automatically mapped to OpenRouter format:
#   - unsloth/Qwen3-VL-30B-A3B-Instruct -> qwen/qwen3-vl-30b-a3b-instruct (recommended, available on OpenRouter)
#   - unsloth/Qwen3-VL-32B-Instruct -> qwen/qwen3-vl-32b-instruct (may be unavailable)
#   - unsloth/Qwen3-VL-8B-Instruct -> qwen/qwen3-vl-8b-instruct
#   - Qwen/Qwen2.5-VL-32B-Instruct -> qwen/qwen2.5-vl-32b-instruct
# 
# Recommended: Use Qwen3-VL-30B-A3B-Instruct for OpenRouter (available at https://openrouter.ai/qwen/qwen3-vl-30b-a3b-instruct)
# For vLLM, use: unsloth/Qwen3-VL-30B-A3B-Instruct (from ModelScope: https://www.modelscope.ai/models/unsloth/Qwen3-VL-30B-A3B-Instruct)
MODEL_NAME=unsloth/Qwen3-VL-30B-A3B-Instruct

# Box type (default: android)
BOX_TYPE=android

# Maximum turns (default: 20)
MAX_TURNS=20

# ========================================
# Model Hub Configuration
# ========================================

# Model hub to use: "huggingface" or "modelscope"
# ModelScope is faster for users in China
MODEL_HUB=huggingface

# Hugging Face mirror (for China users)
# Default: https://hf-mirror.com
# Original: https://huggingface.co
HF_ENDPOINT=https://hf-mirror.com

# ModelScope cache directory (when using MODEL_HUB=modelscope)
MODELSCOPE_CACHE=$HOME/.cache/modelscope

